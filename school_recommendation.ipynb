{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726ef8f-cced-463c-9a38-c46379a47dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#May need to install the following\n",
    "pip install sentence-transformers\n",
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f53c70-a25a-42d6-80c7-a93766b56e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded school embeddings...\n",
      "Recommended schools based on your preferences:\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n",
      "|    | School Name                             | Languages Taught   | Programmes Offered                          | Special Education Classes   | City     |\n",
      "+====+=========================================+====================+=============================================+=============================+==========+\n",
      "| 19 | Mäkelänrinne Upper Secondary School     | Finnish            | General, Physical education                 | Yes                         | Helsinki |\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n",
      "| 11 | Brändö gymnasium Upper Secondary School | Swedish            | General upper secondary, Physical education | Yes                         | Helsinki |\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "schools_df = pd.read_excel('schools.xlsx')##load schools dataset\n",
    "\n",
    "# User input simulation (replace these with actual input prompts in practice)\n",
    "user_preferences = {\n",
    "    'Languages Taught': 'Finnish, Swedish',\n",
    "    'Programmes Offered': 'Physical Education',\n",
    "    'Special Education Classes': 'Yes',\n",
    "    'City': 'Helsinki'\n",
    "}\n",
    "\n",
    "# Convert user preferences into a search query\n",
    "search_query = ', '.join(user_preferences.values())\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Encode the search query since it changes every time\n",
    "query_embedding = model.encode(search_query)\n",
    "\n",
    "# Specify the path for the school embeddings\n",
    "school_embeddings_path = 'school_embeddings.pkl'\n",
    "\n",
    "# Function to save embeddings\n",
    "def save_embeddings(path, embeddings):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "\n",
    "# Function to load embeddings\n",
    "def load_embeddings(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Check if the school embeddings file exists, if not, create embeddings and save them\n",
    "if not os.path.exists(school_embeddings_path):\n",
    "    school_embeddings = model.encode(schools_df[['Languages Taught', 'Programmes Offered', 'Special Education Classes', 'City']].agg(', '.join, axis=1))\n",
    "    save_embeddings(school_embeddings_path, school_embeddings)\n",
    "    print('School embeddings created and saved...')\n",
    "else:\n",
    "    school_embeddings = load_embeddings(school_embeddings_path)\n",
    "    print('Loaded school embeddings...')\n",
    "\n",
    "\n",
    "# Compute semantic similarity (cosine similarity)\n",
    "similarity_scores = util.pytorch_cos_sim(query_embedding, school_embeddings)\n",
    "\n",
    "# Parameters for filtering\n",
    "threshold = 0.80  # similarity threshold (decrease for more results)\n",
    "top_k = 5  # number of top schools to select\n",
    "\n",
    "# Sort schools based on similarity score and apply threshold\n",
    "sorted_indices = (-similarity_scores).argsort()[0]\n",
    "filtered_indices = [i for i in sorted_indices if similarity_scores[0, i] > threshold]\n",
    "\n",
    "# Check if there are any schools matching the criteria\n",
    "if len(filtered_indices) == 0:\n",
    "    print(\"No schools match your preferences. Please adjust your criteria.\")\n",
    "else:\n",
    "    # Adjust top_k if there are fewer schools than requested\n",
    "    top_school_indices = filtered_indices[:min(top_k, len(filtered_indices))]\n",
    "    recommended_schools = schools_df.iloc[top_school_indices]\n",
    "    if len(recommended_schools) > 0:\n",
    "        print(\"Recommended schools based on your preferences:\")\n",
    "        print(tabulate(recommended_schools, headers='keys', tablefmt='grid'))\n",
    "    else:\n",
    "        print(\"No schools match your preferences after applying the threshold. Please adjust your criteria or threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f689978-b8b8-4f56-b873-c20301f73fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded school embeddings...\n",
      "Recommended schools based on your preferences:\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n",
      "|    | School Name                             | Languages Taught   | Programmes Offered                          | Special Education Classes   | City     |\n",
      "+====+=========================================+====================+=============================================+=============================+==========+\n",
      "| 19 | Mäkelänrinne Upper Secondary School     | Finnish            | General, Physical education                 | Yes                         | Helsinki |\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n",
      "| 11 | Brändö gymnasium Upper Secondary School | Swedish            | General upper secondary, Physical education | Yes                         | Helsinki |\n",
      "+----+-----------------------------------------+--------------------+---------------------------------------------+-----------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Using GPT-4V\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "\n",
    "schools_df = pd.read_excel('schools.xlsx') ##load schools dataset\n",
    "\n",
    "##unique terms in the dataset. Required to ensure correct output from the LLM.\n",
    "languages_taught = schools_df['Languages Taught'].unique().tolist()\n",
    "programmes_offered = schools_df['Programmes Offered'].unique().tolist()\n",
    "special_education_classes = schools_df['Special Education Classes'].unique().tolist()\n",
    "cities = schools_df['City'].unique().tolist()\n",
    "\n",
    "# Configuration\n",
    "GPT4V_KEY = \"\"  ###OpenAI API key required here. I have used GPT-4V model for this experiment.\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "GPT4V_ENDPOINT = \"https://hhazure-openai-dev.openai.azure.com/openai/deployments/GPT4Vision/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "# Your input message\n",
    "input_message = \"Hi. I am a fitness instructor, currently working in Hamberg, Germany. \\\n",
    "I want to visit a suitable Finnish school in Helsinki that offers physical education programmes in Finnish or Swedish, \\\n",
    "preferably with special education classes. My visit will be one week long.\"\n",
    "\n",
    "#System prompt to ensure that the terms come from the \n",
    "system_message = f\"A teacher applies for a school visit through an application form. In a simple description, he mentions his preferences for\\\n",
    "a particular language taught in the school, the programme of his interest, special education class, and city. \\\n",
    "Extract the required languages, programmes, special education class ('yes' or 'not available'), \\\n",
    "and city from the input message. The terms for all these four should come from the following lists: \\\n",
    "Languages Taught: {', '.join(languages_taught)}; \\\n",
    "Programmes Offered: {', '.join(programmes_offered)}; \\\n",
    "Special Education Classes: {', '.join(special_education_classes)}; \\\n",
    "Cities: {', '.join(cities)}. \\\n",
    "Do not make up any term. If you don't find a matching term, return 'not available' for its response. \\\n",
    "Your output should only be the extracted terms separated by a comma.\"\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_message\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 800\n",
    "}\n",
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code.\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response\n",
    "response_json = response.json()  # Assuming 'response' is your response object\n",
    "search_query = response_json['choices'][0]['message']['content'] if response_json.get('choices') else \"No response content.\"\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Encode the search query and school data\n",
    "query_embedding = model.encode(search_query)\n",
    "\n",
    "# Specify the path for the school embeddings\n",
    "school_embeddings_path = 'school_embeddings2.pkl'\n",
    "\n",
    "# Function to save embeddings\n",
    "def save_embeddings(path, embeddings):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "\n",
    "# Function to load embeddings\n",
    "def load_embeddings(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Check if the school embeddings file exists, if not, create embeddings and save them\n",
    "if not os.path.exists(school_embeddings_path):\n",
    "    school_embeddings = model.encode(schools_df[['Languages Taught', 'Programmes Offered', 'Special Education Classes', 'City']].agg(', '.join, axis=1))\n",
    "    save_embeddings(school_embeddings_path, school_embeddings)\n",
    "    print('School embeddings created and saved...')\n",
    "else:\n",
    "    school_embeddings = load_embeddings(school_embeddings_path)\n",
    "    print('Loaded school embeddings...')\n",
    "\n",
    "# Compute semantic similarity\n",
    "similarity_scores = util.pytorch_cos_sim(query_embedding, school_embeddings)\n",
    "\n",
    "# Parameters for filtering\n",
    "threshold = 0.80  # similarity threshold\n",
    "top_k = 5  # number of top schools to select\n",
    "\n",
    "# Sort schools based on similarity score and apply threshold\n",
    "sorted_indices = (-similarity_scores).argsort()[0]\n",
    "filtered_indices = [i for i in sorted_indices if similarity_scores[0, i] > threshold]\n",
    "\n",
    "# Check if there are any schools matching the criteria\n",
    "if len(filtered_indices) == 0:\n",
    "    print(\"No schools match your preferences. Please adjust your criteria.\")\n",
    "else:\n",
    "    # Adjust top_k if there are fewer schools than requested\n",
    "    top_school_indices = filtered_indices[:min(top_k, len(filtered_indices))]\n",
    "    recommended_schools = schools_df.iloc[top_school_indices]\n",
    "    if len(recommended_schools) > 0:\n",
    "        print(\"Recommended schools based on your preferences:\")\n",
    "        print(tabulate(recommended_schools, headers='keys', tablefmt='grid'))\n",
    "    else:\n",
    "        print(\"No schools match your preferences after applying the threshold. Please adjust your criteria or threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b6183-5998-4407-8a0a-cae4e2e77232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
